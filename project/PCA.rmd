---
title: "Principal Components and Partial Least Squares analysis in data with different correlation structure"
subtitle: "Computational Statistics, University of Bonn 2022"
author: "Krasimira Kirilova"
date: "August 23, 2022"
output: 
  pdf_document:
    toc: true
    number_sections: true
fontsize: 12pt
geometry: "margin=1in"
urlcolor: blue
bibliography: "./references.bib"
nocite: "@*"
---

```{r setup, include=FALSE} 
knitr::opts_chunk$set(warning = FALSE, message = FALSE) 
```

```{r eval = TRUE, echo = FALSE, message = FALSE, warning=FALSE}
source("functions/data_utils.R")
source("functions/model_utils.R")
source("functions/plotting_utils.R")
source("functions/constants.R")
source("functions/helpers.R")
source("functions/generate_data.R")
source("functions/simulation.R")
source("functions/run_simulations.R")
```

```{r eval = TRUE, echo = FALSE, message = FALSE, warning=FALSE}
library("pls") # PCA and PLS regression
library("corrplot") # create correlation plots
library("readxl") # read Excel files
library("MASS")
library("xts") #time series conversion
library("zoo") # time series
library("knitr") # rendering engine
```


```{r eval = TRUE, echo = FALSE, message = FALSE, warning=FALSE}
# Global variables
simulation_option_default <- list(N = possible_N[1],
                                  p = 20,
                                  runs = 100,
                                  ncomp = NULL)
dgp_option_default <- list(BETAS_INCREASE_FACTOR = 4, error_term_constant = 4)
```

\newpage

# Introduction
Economic phenomena, both micro and macro, has always been influenced by a large number of variables. Difficulties in data collection and lack of computational power in the past imposed usage of small structural models for forecasting. Nowadays we can employ several techniques and methods to forecast economic variables using high-dimensional data. Principal component analysis(PCA) is a wildly common method for dimension reduction. The basic idea is to transform the original data in such way as to use smaller number of factors in our prediction instead of the original number of variables. Partial Least Squares(PLS) constructs the factors such that the covariance between the factors and the target variable is maximized. My goal with this project is to explore the kinds of data structure where PCA performs poorly. In the literature one of the cases studied is high-dimensional data where one variable is highly important for the target variable and the other variables are not. The many noisy variables tend to  mask the signal in the leading variable when constructing the factors, leading to worse prediction.
The project is organized into Theoretical background section and simulation and empirical application sections. For the lather sections I take guidance from [@groen2009revisiting] and use data set from [@stock2009forecasting].


# Theorethical background of PCA and PLS
As [@jolliffe202250] writes, the first workings in PCA are from Pearson and later Hotelling in the first years of the 20th century. Decades after its creation, the developments in the method were focused on theory. The first applications to real data were done in the 60s with data sets containing 11-15 variables. Nowadays, PCA is used in variety of academic disciplines, industrial organizations and government agencies.

## Principal component analysis
Given an ${n}\times{p}$ matrix $X$ PCA creates orthogonal linear combinations of the columns of $X$ and finds the projections which maximize the variance. The first principal component contains projections along the direction with the most variance. We derive principal components by decomposing the matrix $X$ and deriving the eigen vectors. An $m \times n$ matrix $M$ can be written in the form

\[
  \makebox[\linewidth]{$\displaystyle
  \begin{aligned}
    M = U \Sigma V^{*}
  \end{aligned}
  $}
\]

$U$ being an $m \times n$ unitary matrix, $\Sigma$ is a diagonal $m \times n$ matrix, $V$ is an $n \times n$ unitary matrix and $V^{*}$ is the conjugate transpose of $V$, also unitary.
In a similar manner, our data matrix $X$ can be decomposed as

\[
  \makebox[\linewidth]{$\displaystyle
  \begin{aligned}
      X &= U\Sigma V^{*}  \\
      X^{T}X &= (U\Sigma V^{*})^{T} (U\Sigma V^{*}) \\
      (X^{T}X)V &= V \Sigma^{2} V^{*}V \\
      (X^{T}X)V &= V \Sigma^{2}
  \end{aligned}
  $}
\]

where $V$ is the matrix of eigen vectors of $X^{T}X$ and $\Sigma^{2}$ is the square matrix with eigen values in the diagonal. The eigen vectors are sorted by eigen values from biggest to lowest.
Now, with our eigen vectors sorted, we can project $X$ on the new space 
\[
  \begin{aligned}
    Z&=XV
  \end{aligned}
\]

The elements of $V$ are called principal component loadings.
The columns of $Z$ are the principal components and the elements of $Z$, $z_{i1}, ... , z_{in}$ are the principal component scores.
Thus, the first principal component contains up to $N - 1$ of the original columns of $X$

\[
  \begin{aligned}
    Z_{1} = \phi_{11}X_{1} + \phi_{21}X_{2} + ... + \phi_{N-1,1}X_{N-1}
  \end{aligned}
\]

Couple of assumptions need to be made for PCA to perform well.
First, the original data needs to be standardized in order to compare the covariance between variables. Secondly, data needs to be linear, proper transformations to the original data have to be performed when this is not the case. Thirdly, the data should not have too many outliers - PCA will give more weight to highly variable features even if the variance is governed by a few outliers. 

## Partial Least Squares
PCA creates linear combinations that represent the original data without including the target variable. Directions that explain the original data best does not necessarily translate to directions in the data which predict the response well.
PLS is an alternative dimension reduction method that takes the response variable into account. PLS identifies a set of features $Z_{1},...Z_{M}$ that are linear combinations of the original features and then fits a linear model using the new set of $M$ features. Unlike PCR, PLS will not only create features that best represent the original data but also creates features that are related to the response variable. The first component in PLS is calculated by setting each principal component loading $\phi_{j1}$ to the coefficient from the linear regression of $Y$ onto $X_{j}$. The highest PLS loadings correspond to the variables that are strongly related to $Y$.
In a high-dimensional setting where one or couple of variables explains the target variable well, we'll expect PLS to outperform PCR.

# Simulation
The simulation study is inspired by [@groen2009revisiting]. In the paper the authors compare PCR to PLS and Bayesian regression in data with different factor structures. I compare only PCR to PLS and leave Bayesian regression out. 

## Setup
One of the issues with principal components extracted from large number of variables is that there is no guarantee that the components will forecast the target variable well. [@boivin2006more] show that if the forecasting accuracy is driven by a certain factor, this factor can be dominated by other non-informative factors in a large data set. I simulate high dimensional data with different correlation structure under five cases: 

1. Data set where one variable is highly related with the outcome variable. 
2. Data set where 1/3 of the variables are highly correlated. 
3. Data set where 10% of the variables are highly correlated. 
4. Data set where all variables are highly correlated. 
5. Data set with no high correlation between variables. 

Correlation in the data for all cases is shown below.  

```{r eval = TRUE, echo = FALSE, results='hide', message = FALSE, warning=FALSE}
# Plotting data correlation ----
plotting <- new.env()

plotting$sim_option <- simulation_option_default
plotting$sim_option$runs <- 1
plotting$sim_option$N <- 100
plotting$sim_option$p <- 10
plotting$result <- simulation(dgp_option_list = dgp_option_default, simulation_option_list = plotting$sim_option)

# Show 3 plots on a row in 2 rows
# mar argument makes the plot title visible(corrplot bug)
{par(mfrow=c(2,3))
corrplot::corrplot(cor(plotting$result$data[[1]]), title = "Case 1", mar=c(0,0,2,0))
corrplot::corrplot(cor(plotting$result$data[[2]]), title = "Case 2", mar=c(0,0,2,0))
corrplot::corrplot(cor(plotting$result$data[[3]]), title = "Case 3", mar=c(0,0,2,0))
corrplot::corrplot(cor(plotting$result$data[[4]]), title = "Case 4", mar=c(0,0,2,0))
corrplot::corrplot(cor(plotting$result$data[[5]]), title = "Case 5", mar=c(0,0,2,0))}
```

The coefficients $\beta$ are generated randomly and transformed according to the cases. In the first case, I inflate the first coefficient when creating the response variable. In the other cases I inflate the coefficients proportionally to the transformed variables, where in the fifth case the proportion is 0 and the coefficients are left without transformation.

The simulations are performed using $N = 100, 200, 400, 192$ as number of observations, $p = 20, 100, 108$ as number of variables and are run 100 times, with exception of one simulation which was run for 1000 times. Models are evaluated on a training set, representing 1/2 of the sample, and predictions are made on a test set.


## Simulation Results

### Results without setting the number of components used for prediction

In the first four simulations I vary $N$ through $N = 100, 200, 400$ and set the number of variables at $p = 20, 100$ where $p = 20$ for the first three simulations and $p = 100$ for the last one. The number of principal components used are determined by the number of components which correspond to the minimum RMSEP of the model. The change in MSE between PCR and PLSR is not quite different between the simulations, where PLSR outperforms PCR in all cases except data set with 10% of the variables are highly correlated. Both methods use 2/3 number components out of available variables in prediction on average. Poorer performance of PLSR may be attributed to bias in the regression coefficients used in constructing the principal component. Also, the small MSE in both models signals overfitting. Overall, with 2/3 variables used the difference between the methods is negligible. PLSR achieves lower MSE since it uses the response variable to construct the principal components.

```{r eval = TRUE, echo = FALSE, results='hide', message = FALSE, warning=FALSE}
# Simulation plots
load(file = "simulation_results_Rdata/simulation4.RData")

simulation_plotting <- new.env()

simulation_plotting$pcr_plsr_mean_mat <- matrix(nrow = 2, ncol = 5)
simulation_plotting$pcr_plsr_mean_mat[1, ] <- colMeans(simulation4$result$MSE_PCR)
simulation_plotting$pcr_plsr_mean_mat[2, ] <- colMeans(simulation4$result$MSE_PLSR)

rownames(simulation_plotting$pcr_plsr_mean_mat) <- c("PCR", "PLSR")
colnames(simulation_plotting$pcr_plsr_mean_mat) <- c("Case 1", "Case 2", "Case 3", "Case 4", "Case 5")
{
  barplot(
    simulation_plotting$pcr_plsr_mean_mat,
    beside = TRUE,
    main = "MSE PCR and PLSR Simulation 4",
    ylab = "MSE",
    col = c("dodgerblue", "dodgerblue4")
  )
  legend("center",
         c("PCR", "PLSR"),
         fill = c("dodgerblue", "dodgerblue4"))
}

# {par(mfrow = c(2, 3))
# plot_MSE_comparison_boxplot(simulation4$result, simulation4$MSE_stats)}
```

### Results with setting the number of principal components used for prediction
In next simulations, $N$ is set to $200, 192$, $p$ to $100, 108$ and the number of principal components used for prediction is varying $r = 1, 3, 6$. One simulation runs for 1000 times, all others for 100. $N = 192$ and $p = 108$ are chosen out of our real data set where we have 192 observations and 108 variables.

When using smaller number of components again PLSR outperforms PCR in almost all cases. The only case where PCR performs better is in the case where all variables are correlated - this case is most likely to lead to overfitting compared to other cases, but even in this case when we increase the number of principal components used to six, the difference in MSE between PCR and PLSR drops to 0. PLSR performs better with less principal components used - PLSR gives way smaller MSE for one principal components used than PCR. This is not surprising given the workings of PLSR. For the most extreme cases - case where one variable is the most important for the target variable and where there is not leading variable explaining the target variable - PLSR again outperforms PCR. Mean MSE for cases 1 and 5 over simulations with different number of components used for PLSR are 40 and 73 respectively. For PCR the results are 107 mean MSE over simulations in case 1 and 73 mean MSE for case 5.  


```{r, eval = FALSE, echo = FALSE, message = FALSE, warning=FALSE}


# Simulation 1: N = 100, p = 20, runs = 100, use optimal component number ----
run_simulation1(simulation_option_default, dgp_option_default)

# Simulation 2: N = 200, p = 20, use optimal number of components ----
run_simulation2(simulation_option_default, dgp_option_default)

# Simulation 3: N = 400, p = 20, use optimal number of components ----
run_simulation3(simulation_option_default, dgp_option_default)

# Simulation 4: N = 200, p = 100, use optimal number of components ----
run_simulation4(simulation_option_default, dgp_option_default)

# Simulation 5: N = 200, p = 100, ncomp = 6 ----
run_simulation5(simulation_option_default, dgp_option_default)

# Simulation 6: N = 200, p = 100, ncomp = 3 ----
run_simulation6(simulation_option_default, dgp_option_default)

# Simulation 7: N = 200, p = 100, ncomp = 1 ----
run_simulation7(simulation_option_default, dgp_option_default)

# Simulation 8: N = 192, p = 108, ncomp = 6, runs = 1000 ----

# Simulation takes a lot of time
# run_simulation8(simulation_option_default, dgp_option_default)

# Simulation 9: N = 192, p = 108, ncomp = 6, runs = 100 ----
run_simulation9(simulation_option_default, dgp_option_default)

# Simulation 10: N = 192, p = 108, ncomp = 3, runs = 100 ----
run_simulation10(simulation_option_default, dgp_option_default)

# Simulation 11: N = 192, p = 108, ncomp = 1, runs = 100 ----
run_simulation11(simulation_option_default, dgp_option_default)
```
 


# Empirical Applicaiton

To test the performance of PCR and PLSR with realistic settings, I use [@groen2009revisiting] and the data set from [@stock2009forecasting].

## Data set and variables
The data set consists of 108 macroeconomic variables in a panel going from January 1959 to December 2006. The variables used for prediction are *CPI inflation*,  *industrial production*, *unemployment rate* and the *federal funds rate*. The raw data is transformed using transformation information for every variable in order to create stationary series of data. 
The forecasts are performed over three samples from the data: from January 1972 to December 2006, from January 1972 to December 1984 and from January 1985 to December 2006. The models are trained on sample from January 1959 to December 1971. The forecasts are updated on a window of data for every year in the sample (h = 12). The predictions from the models are tested using different number of components. For PCR, the number of components are $r = 2, 4, 6$ and for PLSR $r = 1, 2, 3$. Finally, MSE is recorder for all sub-samples and number of components and the percentage change in MSE between PCR and PLSR is reported for every sample and variable.


```{r, results='hide', echo=FALSE, eval = TRUE, message=FALSE}
# Load Data set
load(file = "../data/data/WORKING_DATA.rda")
application <- new.env()
# Variables to forecast:
# CPI inflation
# (aggregate) industrial production, 
# (aggregate) unemployment rate
# (effective) federal funds rate
# CONSTANTS ----
application$variables_to_predict <- c("CPIAUCSL", "IPS10", "LHUR", "FYFF")
application$h <- 12 # c(3, 12, 24)
application$PCR_ncomp <- c(2, 4, 6)
application$PLSR_ncomp <- c(1, 2, 3)
# Number of component cases: for now 3 cases for both methods.
application$number_of_components <- length(application$PCR_ncomp)
# END CONSTANTS ----

# Get data set end date(Note: this could be a constant, but again if you change the file now including later years this code will work automatically)
application$data_end_date <- tail(zoo::as.Date(WORKING_DATA$rawdata), n = 1)
application$data_first_date <- head(zoo::as.Date(WORKING_DATA$rawdata), n = 1)
application$train_end_date <- string_date_to_vector_date("1971-10-01") #zoo::as.Date("1971-10-01")

application$train_data_ts <- get_transformed_time_series(WORKING_DATA, enddate = application$train_end_date)
application$data_as_ts <- get_transformed_time_series(WORKING_DATA, enddate = application$data_end_date)

# plot.ts(application$train_data_ts[, application$variables_to_predict])


set.seed(2456)
application$train_data_ts_cleared <- application$train_data_ts[-(is.na(application$train_data_ts) == TRUE), ]

# Run models on train data. Then predictions will be made on 3 samples
pcr <- new.env()
pcr$CPIAUCSL_model <- pcr(CPIAUCSL ~ ., data = application$train_data_ts, scale = TRUE, validation = "CV")
pcr$IPS10_model <- pcr(IPS10 ~ ., data = application$train_data_ts, scale = TRUE, validation = "CV")
pcr$LHUR_model <- pcr(LHUR ~ ., data = application$train_data_ts, scale = TRUE, validation = "CV")
pcr$FYFF_model <- pcr(FYFF ~ ., data = application$train_data_ts, scale = TRUE, validation = "CV")


plsr <- new.env()
plsr$CPIAUCSL_model <- plsr(CPIAUCSL ~ ., data = application$train_data_ts, scale = TRUE, validation = "CV")
plsr$IPS10_model <- plsr(IPS10 ~ ., data = application$train_data_ts, scale = TRUE, validation = "CV")
plsr$LHUR_model <- plsr(LHUR ~ ., data = application$train_data_ts, scale = TRUE, validation = "CV")
plsr$FYFF_model <- plsr(FYFF ~ ., data = application$train_data_ts, scale = TRUE, validation = "CV")

# end date: string_date_to_vector_date("2006-10-01")

application$first_sample_period <- list(startdate =
                                           string_date_to_vector_date("1972-01-01"),
                                         enddate = application$data_end_date)
application$second_sample_period <- list(startdate =
                                           string_date_to_vector_date("1972-01-01"),
                                         enddate = string_date_to_vector_date("1984-10-01"))

application$third_sample_period <- list(startdate =
                                           string_date_to_vector_date("1985-01-01"),
                                         enddate = application$data_end_date)
application$first_sample <-
  window(
    application$data_as_ts,
    start = application$first_sample_period$startdate,
    end = application$first_sample_period$enddate
  )

application$second_sample <-
  window(
    application$data_as_ts,
    start = application$second_sample_period$startdate,
    end = application$second_sample_period$enddate
  )

application$third_sample <-
  window(
    application$data_as_ts,
    start = application$third_sample_period$startdate,
    end = application$third_sample_period$enddate
  )

# sample_name: first_sample, second_sample, third_sample. Should be ready before invoking this function
# sample: the actual sample, ts object
predict_by_sample <- function(sample_name, sample, sample_start_date, sample_name_short){
  runs <-
    (nrow(application[[sample_name]]) / 4)
  
  # This will create MSE matrix with column names components used in prediction, so we'll store MSE for 2 components used, 4 and 6
  pcr$CPIAUCSL[[sample_name]]$MSE <-
    matrix(
      nrow = runs,
      ncol = application$number_of_components,
      dimnames = list(NULL, application$PCR_ncomp)
    )
  pcr$FYFF[[sample_name]]$MSE <-
    matrix(
      nrow = runs,
      ncol = application$number_of_components,
      dimnames = list(NULL, application$PCR_ncomp)
    )
  pcr$IPS10[[sample_name]]$MSE <-
    matrix(
      nrow = runs,
      ncol = application$number_of_components,
      dimnames = list(NULL, application$PCR_ncomp)
    )
  pcr$LHUR[[sample_name]]$MSE <-
    matrix(
      nrow = runs,
      ncol = application$number_of_components,
      dimnames = list(NULL, application$PCR_ncomp)
    )
  
  # # This will create MSE matrix with column names components used in prediction, so we'll store MSE for 1 components used, 2 and 3(in this case the same as normal index, but it's implemented in the same way for consistency)
  plsr$CPIAUCSL[[sample_name]]$MSE <-
    matrix(
      nrow = runs,
      ncol = application$number_of_components,
      dimnames = list(NULL, application$PLSR_ncomp)
    )
  plsr$FYFF[[sample_name]]$MSE <-
    matrix(
      nrow = runs,
      ncol = application$number_of_components,
      dimnames = list(NULL, application$PLSR_ncomp)
    )
  plsr$IPS10[[sample_name]]$MSE <-
    matrix(
      nrow = runs,
      ncol = application$number_of_components,
      dimnames = list(NULL, application$PLSR_ncomp)
    )
  plsr$LHUR[[sample_name]]$MSE <-
    matrix(
      nrow = runs,
      ncol = application$number_of_components,
      dimnames = list(NULL, application$PLSR_ncomp)
    )
  
  
  for (i in 1:runs) {
    prediction_sample <-
      window(application[[sample_name]],
             end = sample_start_date[1] + i)
    
    CPIAUCSL_x <-
      model.matrix(CPIAUCSL ~ ., data = prediction_sample)[, -1]
    CPIAUCSL_y <-
      prediction_sample[, "CPIAUCSL"]
    
    FYFF_x <-
      model.matrix(FYFF ~ ., data = prediction_sample)[, -1]
    FYFF_y <-
      prediction_sample[, "FYFF"]
    
    IPS10_x <-
      model.matrix(IPS10 ~ ., data = prediction_sample)[, -1]
    IPS10_y <-
      prediction_sample[, "IPS10"]
    
    LHUR_x <-
      model.matrix(LHUR ~ ., data = prediction_sample)[, -1]
    LHUR_y <-
      prediction_sample[, "LHUR"]
    
    for (j in application$PCR_ncomp) {
      pcr$CPIAUCSL[[sample_name]]$predicted <-
        predict(pcr$CPIAUCSL_model, CPIAUCSL_x, ncomp = j)
      
      pcr$CPIAUCSL[[sample_name]]$MSE[i, as.character(j)] <-
        get_MSE(pcr$CPIAUCSL[[sample_name]]$predicted,
                CPIAUCSL_y)
      
      pcr$FYFF[[sample_name]]$predicted <-
        predict(pcr$FYFF_model, FYFF_x, ncomp = j)
      
      pcr$FYFF[[sample_name]]$MSE[i, as.character(j)] <-
        get_MSE(pcr$FYFF[[sample_name]]$predicted,
                FYFF_y)
      
      pcr$IPS10[[sample_name]]$predicted <-
        predict(pcr$IPS10_model, IPS10_x, ncomp = j)
      
      pcr$IPS10[[sample_name]]$MSE[i, as.character(j)] <-
        get_MSE(pcr$IPS10[[sample_name]]$predicted,
                IPS10_y)
      
      pcr$LHUR[[sample_name]]$predicted <-
        predict(pcr$LHUR_model, LHUR_x, ncomp = j)
      
      pcr$LHUR[[sample_name]]$MSE[i, as.character(j)] <-
        get_MSE(pcr$LHUR[[sample_name]]$predicted,
                LHUR_y)
      
    }
    
    for (g in application$PLSR_ncomp) {
      plsr$CPIAUCSL[[sample_name]]$predicted <-
        predict(plsr$CPIAUCSL_model,
                CPIAUCSL_x,
                ncomp = g)
      
      plsr$CPIAUCSL[[sample_name]]$MSE[i, as.character(g)] <-
        get_MSE(plsr$CPIAUCSL[[sample_name]]$predicted,
                CPIAUCSL_y)
      
      plsr$FYFF[[sample_name]]$predicted <-
        predict(plsr$FYFF_model, FYFF_x, ncomp = g)
      
      plsr$FYFF[[sample_name]]$MSE[i, as.character(g)] <-
        get_MSE(plsr$FYFF[[sample_name]]$predicted,
                FYFF_y)
      
      plsr$IPS10[[sample_name]]$predicted <-
        predict(plsr$IPS10_model, IPS10_x, ncomp = g)
      
      plsr$IPS10[[sample_name]]$MSE[i, as.character(g)] <-
        get_MSE(plsr$IPS10[[sample_name]]$predicted,
                IPS10_y)
      
      plsr$LHUR[[sample_name]]$predicted <-
        predict(plsr$LHUR_model, LHUR_x, ncomp = g)
      
      plsr$LHUR[[sample_name]]$MSE[i, as.character(g)] <-
        get_MSE(plsr$LHUR[[sample_name]]$predicted,
                LHUR_y)
    }
  }
  
  for (h in application$variables_to_predict) {
    pcr[[h]][[sample_name]]$MSE_mean <- rep(0, length(application$PCR_ncomp))
    names(pcr[[h]][[sample_name]]$MSE_mean) <- application$PCR_ncomp
    
    for (hhh in application$PCR_ncomp) {
      pcr[[h]][[sample_name]]$MSE_mean[as.character(hhh)] <-
        mean(pcr[[h]][[sample_name]]$MSE[, as.character(hhh)])
    }
  }
  
  
  for (k in application$variables_to_predict) {
    plsr[[k]][[sample_name]]$MSE_mean <- rep(0, length(application$PLSR_ncomp))
    names(plsr[[k]][[sample_name]]$MSE_mean) <- application$PLSR_ncomp
    
    for (hh in application$PLSR_ncomp) {
      plsr[[k]][[sample_name]]$MSE_mean[as.character(hh)] <-
        mean(plsr[[k]][[sample_name]]$MSE[, as.character(hh)])
    }
  }
  
  application[[sample_name_short]]$percentage_change_PCR_PLSR <- list()
  
  for (l in application$variables_to_predict) {
    application[[sample_name_short]]$percentage_change_PCR_PLSR[[l]] <-
      mapply(
        get_percantage_change_MSE,
        pcr[[l]][[sample_name]]$MSE_mean,
        plsr[[l]][[sample_name]]$MSE_mean
      )
  }
}

# Prediction based on first sample
predict_by_sample(sample_name = "first_sample", sample = application$first_sample, sample_start_date = application$first_sample_period$startdate, sample_name_short = "FS")

# Prediction based on second sample
predict_by_sample(
  sample_name = "second_sample",
  sample = application$second_sample,
  sample_start_date = application$second_sample_period$startdate,
  sample_name_short = "SS"
)

# Prediction based on third sample
predict_by_sample(
  sample_name = "third_sample",
  sample = application$third_sample,
  sample_start_date = application$third_sample_period$startdate,
  sample_name_short = "TS"
)

# # PLOTTING ----
# application$results$PCR$LHUR_first_sample <-
#   ts(
#     pcr$LHUR$first_sample$predicted,
#     start = application$first_sample_period$startdate,
#     frequency = 4
#   )
# 
# application$results$PLSR$LHUR_first_sample <-
#   ts(
#     plsr$LHUR$first_sample$predicted,
#     start = application$first_sample_period$startdate,
#     frequency = 4
#   )
# 
# application$results$LHUR_first_sample_time <-
#   as.yearqtr(time(application$results$PCR$LHUR_first_sample))
# 
# {
#   plot(
#     x = application$results$LHUR_first_sample_time,
#     y = application$results$PCR$LHUR_first_sample,
#     type = "l",
#     col = "goldenrod1",
#     main = "First sample PCR results for unemployment rate",
#     xlab = "Time",
#     ylab = "LHUR",
#   )
#   lines(
#     x = application$results$LHUR_first_sample_time,
#     y = application$results$PLSR$LHUR_first_sample,
#     col = "goldenrod4"
#   )
#   lines(
#     x = application$results$LHUR_first_sample_time,
#     y = application$first_sample[, "LHUR"],
#     lwd=2.0,
#     col = "dodgerblue3"
#   )
#   # Add a legend
#   legend(
#     "topleft",
#     legend = c("PCR", "PLSR" , "Actual"),
#     col = c("goldenrod1", "goldenrod4", "dodgerblue3"),
#     lty = 1:1:1,
#     cex = 0.8
#   )
# }

```
## Application results
I report the results using difference in MSE between PCR and PLSR in percent. Positive values indicate PLSR performed better than PCR and negative values report cases where PCR MSE was lower than PLSR MSE.  
We can see the forecast performance of the methods in the three samples and for different number of components used. Cases are grouped by number of components used for each method - for PCR number of components are 2,4,6 and for PLSR number of components used are 1,2,3. Number of components used in the forecast in denoted by $r = n1, n2$ in the table output.

In the first sample, PCR outperforms PLSR for all number of components only for the unemployment rate where we see big differences in MSE for both methods. CPI inflation is predicted better by PLSR for all components. This may be the case because of substantial differences between the training set and the first test sample. 

```{r echo = FALSE}
{par(mfrow=c(1,2))
plot(application$train_data_ts[, "LHUR"], xlab="Time", ylab = "Unemployment rate", main = "LHUR in training data")
plot(application$first_sample[, "LHUR"], xlab="Time", ylab = "Unemployment rate", main = "LHUR in first sample")}
```

Indeed, the variation in the unemployment rate in the training set is much bigger than in the first sample. The same is true for the second sample. The dynamics in the variable are matched for the third sample only where we see that PLSR outperforms PCR in the case where small number of components(one and two respectively) are used. PLSR produces smaller MSE for CPI inflation in the first and second samples, and PCR performs better in the third sample. For CPI inflation the reasons seem to be the same as for the unemployment rate - differences between the training set and the test sets. Industrial production index is predicted better by PLSR in the first and second samples by using either one or three components. PLSR has greater MSE for industrial production index in the first two samples when we use two principal components. In the third sample, PLSR outperforms PCR only when we include three principal components in the prediction. The federal funds rate is predicted better by PLSR when we use one principal component in all samples. PCR reports smaller MSE for the federal funds rate when six principal components are used and this is true for all samples.

```{r echo = FALSE, results='asis'}


tables <- new.env()
tables$column_names <- c("r = 1, 2", "r = 2, 4", "r = 3, 6")
tables$row_names <- c("CPI inflation", "Industrial index", "Unemployment rate", "Federal funds rate")

tables$FS <- matrix(nrow = 4, ncol = 3)
colnames(tables$FS) <- tables$column_names
rownames(tables$FS) <- tables$row_names

tables$FS[1, ] <- paste(round(application$FS$percentage_change_PCR_PLSR$CPIAUCSL, digits = 2), "%")
tables$FS[2, ] <- paste(round(application$FS$percentage_change_PCR_PLSR$IPS10, digits = 2), "%")
tables$FS[3, ] <- paste(round(application$FS$percentage_change_PCR_PLSR$LHUR, digits = 2), "%")
tables$FS[4, ] <- paste(round(application$FS$percentage_change_PCR_PLSR$FYFF, digits = 2), "%")

knitr::kable(tables$FS, format = "simple", caption = "First sample results", align = "lccrr")

tables$SS <- matrix(nrow = 4, ncol = 3)
colnames(tables$SS) <- tables$column_names
rownames(tables$SS) <- tables$row_names

tables$SS[1, ] <- paste(round(application$SS$percentage_change_PCR_PLSR$CPIAUCSL, digits = 2), "%")
tables$SS[2, ] <- paste(round(application$SS$percentage_change_PCR_PLSR$IPS10, digits = 2), "%")
tables$SS[3, ] <- paste(round(application$SS$percentage_change_PCR_PLSR$LHUR, digits = 2), "%")
tables$SS[4, ] <- paste(round(application$SS$percentage_change_PCR_PLSR$FYFF, digits = 2), "%")

knitr::kable(tables$SS, format = "simple", caption = "Second sample results", align = "lccrr")

tables$TS <- matrix(nrow = 4, ncol = 3)
colnames(tables$TS) <- tables$column_names
rownames(tables$TS) <- tables$row_names

tables$TS[1, ] <- paste(round(application$TS$percentage_change_PCR_PLSR$CPIAUCSL, digits = 2), "%")
tables$TS[2, ] <- paste(round(application$TS$percentage_change_PCR_PLSR$IPS10, digits = 2), "%")
tables$TS[3, ] <- paste(round(application$TS$percentage_change_PCR_PLSR$LHUR, digits = 2), "%")
tables$TS[4, ] <- paste(round(application$TS$percentage_change_PCR_PLSR$FYFF, digits = 2), "%")

knitr::kable(tables$TS, format = "simple", caption = "Third sample results", align = "lccrr")

```

# Conclusion
For most applications the difference between PCR and PLSR is not substantial - both methods seem to perform the same. An important distinction between the workings of the methods arises from the underlying data structure on which they are performed. PCR is most beneficial in data setting without unique variation - all variables seem to move together. When we introduce correlation in clusters or neighborhoods of the data cloud, PLSR performs slightly better as it is able to capture the relationship between the features and the target variable. In a data set with one dominant factor explaining the target variable, PCR tends to aggregate all variables and diminish the importance of this one factor, while PLSR is able to capture the relationship and place greater predictive power on that one predictor variable - MSE for PLSR will drop substantially on the first principal component and all other components will not improve the prediction by much. Overall, the choice between PCR and PLSR lies in the structure of the data set at hand.  

\newpage

# References